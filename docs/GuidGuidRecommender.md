
# Overview

The GUID-GUID coinstallation recommender system generates recommendations
for add-ons which are similar to a given add-on,
where similarity is based on the number of profiles
which have both add-ons installed.

As recommendations are only surfaced
for a specific set of add-ons meeting certain criteria,
and depend only on characteristics of the add-ons themselves,
recommendation sets for each add-on can be (and are) computed in advance.

Recommendations are generated as follows:

1. The [input data](#input-data),
    consisting of coinstallation counts for each pair of add-ons,
    is loaded from a precomputed file.
2. For each add-on, we determine a [__candidate list__](#generating-the-scored-candidate-lists) of "related" add-ons,
    together with associated __relevance scores__,
    based on the coinstallation data.
3. Recommendations for a given add-on are [selected](#selecting-recommendations)
    by retaining the N add-ons in the candidate list
    with the highest relevance scores.

Once the recommender has been trained,
we apply various [metrics](#quality-and-health-metrics)
to the coinstallation data, candidate lists, and recommendations,
to evaluate the overall health of the system
and the quality of recommendations.

The recommender system is implemented by the [`GuidGuidCoinstallRecommender`](../taar_lite/recommenders/guidguid.py#L10) class,
which is instantiated by the [TaarLiteAppResource](../taar_lite/app/production.py#L44).


# Input data

The primary data source used in generating recommendations
is the file `guid_coinstallation.json`,
which is generated by the ETL jobs described in the [README](../README.md).
It contains coinstallation counts for each pair of add-ons
belonging to a filtered list.

Coinstallation counts are computed based on the Telemetry data
submitted by a random sample of recently active Firefox profiles.
For each pair of add-ons in the list,
we count the number of profiles in which both add-ons are installed and enabled.

The data is stored in "sparse matrix representation" as a nested object/dict,
in which each add-on GUID maps to a further object
mapping coinstalled GUIDS to their coinstallation count,
dropping zero counts.
On initializing a [`GuidGuidCoinstallRecommender`](../taar_lite/recommenders/guidguid.py#L10),
it is supplied as `raw_coinstall_dict`.

Using this dataset as the basis for recommendations
entails the following assumptions:

- The set of add-ons appearing in the coinstallation dataset represent
    the universe of known add-ons for the purpose of generating recommendations.
- We are only dealing with add-ons that were coinstalled
    with at least one other add-on on the list
    (otherwise they would not appear in the file at all).
- Profiles with only a single add-on installed do not contribute to the counts.

__TODO:__ How are system add-ons handled? Add a note about this.

In computing relevance scores, we also draw on an auxiliary dataset
containing an overall ranking for each add-on in our list,
read from the file `guid_install_ranking.json`.
This is used to break ties when sorting candidates on relevance score,
and in pruning out rare add-ons.
It is currently computed from overall add-on installation counts
obtained from AMO.

This data is stored as an object/dict mapping add-on GUIDs to rank scores.
On initializing a [`GuidGuidCoinstallRecommender`](../taar_lite/recommenders/guidguid.py#L10),
it is supplied as `tie_breaker_dict`.
It is also used as the `ranking_dict` passed to the [`MinInstallPrune`](../taar_lite/recommenders/treatments.py#L36) treatment.


# Generating the scored candidate lists

The TAAR-lite recommender is built on the following underlying principle:
_add-ons which tend to be installed together are similar or complimentary,
and the number of coinstallations indicates the strength of this relationship._
Thus, starting from a given add-on, good recommendations for other add-ons
are those which are most often coinstalled.

Given an add-on A, a natural choice for a candidate list and relevance scores
is then just the list of add-ons that are coinstalled with A,
together with their coinstallation counts.
However, recommendation quality can be improved by making certain adjustments
to these preliminary scored lists, such as:

- tempering the influence of highly popular add-ons
    so that they don't drown out more relevant, less common ones
- pruning out obscure add-ons
- better balancing relevance against diversity
- improving the experience for users clicking through a chain of recommendations
    on AMO, such as pruning out cyclical recommendations.

Final candidate lists and relevance scores are generated
by applying a sequence of such transformations,
referred to as [__treatments__](#treatments),
to the raw coinstallation data.
As recommendations are based solely on the treated data,
we are assuming that it encapsulates all the information
necessary in generating recommendations.

Treatments are implemented as extensions of the [`BaseTreatment`](../taar_lite/recommenders/treatments.py#L11) class,
which apply a transformation via the `treat()` method.
On initializing a [`GuidGuidCoinstallRecommender`](../taar_lite/recommenders/guidguid.py#L10),
a list of `BaseTreatment` instances are supplied as `treatments`.
When the treated dataset is built, the treatments are applied in sequence
to the raw coinstallation data,
and the result is stored as the recommender instance's `treated_graph`.
Candidate lists and relevance scores are then drawn
from the treated dataset.


# Selecting recommendations

Recommendations for a given add-on A are generated
by ordering A's candidate list by decreasing relevance score
and selecting the first N add-ons from the sorted list.
Ties in relevance score are broken using an additional list
of add-on tie-breaking scores,
by further ordering tied candidates by decreasing tie-breaking score.

Recommendations are requested from a `GuidGuidCoinstallRecommender` instance
using the [`recommend()`](../taar_lite/recommenders/guidguid.py#L123) method.
The list of tie-breaking scores was supplied on initialization as `tie_breaker_dict`.
The double ordering is currently implemented by concatenating the two scores
and applying lexicographical ordering on the result.

The version of the GUID-GUID recommender currently in production
defaults to requesting 4 recommendations for each add-on,
which corresponds to the number of display slots on AMO.


# Graph representation

It is helpful to discuss candidate lists, relevance scores and treatments
in terms of an __add-on relational graph__ structure,
as much of the intuition behind the treatments
is drawn from this representation.

An add-on relational graph is a directed graph $G$ in which:

- each vertex is an add-on appearing in the dataset
- there is an edge from A to B if add-on B is considered _related_ to add-on A
- each edge has an associated weight
    indicating the strength of the relationship.

The data used in generating recommendations can be summarized
by such a graph, where
an add-on's candidate list corresponds to its set of neighbours in the graph,
and relevance scores are given by the edge weights.
In this setting:

- A relational graph is induced directly by the coinstallation data,
    considering add-ons related if they are coinstalled,
    and using coinstallation counts as weights.
- Treatments can be thought of as transformations
    which modify add-on relational graphs by
    adding or deleting edges, or adjusting the edge weights.
- The final selection of recommendations can itself be viewed as a treatment,
    which outputs a graph containing, for each add-on A,
    an edge from A to each of A's N recommendations.

The recommendation algorithm can be rephrased
in terms of this representation as follows:

1. Load the input data and create the __coinstallation graph__.
2. Apply each of the specified treatments in turn to the coinstallation graph,
    resulting in the __treated graph__.
3. Apply the recommendation selection treatment to the treated graph
    to produce the __recommendation graph__.

Note that, since the graph is directed, edges do not necessarily run both ways.
In other words, we allow for a treatment to produce a graph in which
A is related to B but B is not related to A,
for example if it removes edges whose weight falls below a threshold.
However, since the relation of being coinstalled is symmetric,
the initial coinstallation graph is undirected.

A relational graph has an associated __adjacency matrix__ $C$,
in which rows and columns are indexed by add-ons (graph vertices),
and entry $C_{ij}$ contains the weight for edge $(i,j)$
if these two add-ons are connected in the graph, or 0 otherwise.
The initial coinstallation dataset is in fact stored
as a sparse representation of its adjacency matrix.
Since this graph is undirected, the adjacency matrix is symmetric
($C_{ij} = C_{ji}$ for any pair $i,j$).
Also, the row sum (or column sum, by symmetry) for add-on $i$ gives
its overall number of installs across all profiles considered in the dataset.


# Treatments

The following [treatments](../taar_lite/recommenders/treatments.py) are implemented for the `GuidGuidCoinstallRecommender`.


## Normalizations

One issue with drawing recommendations directly
from the raw coinstallation graph
is that popular add-ons can greatly outweigh more relevant add-ons,
since the distribution of add-on install counts is heavily skewed.
If a popular add-on such as AdBlock Plus is coinstalled with a given add-on A,
it will likely have the highest raw count out all add-ons coinstalled with A,
and thus would top the list of recommendations.
Furthermore, such popular add-ons are likely to appear
on most add-ons' coinstall lists.
Thus, we seek to transform coinstallation counts in such a way as to discount
the effect of overall popularity.
This corresponds to adjusting the edge weights in the graph representation.

Note that, even though the raw coinstallation graph is undirected
(with a symmetric adjacency matrix),
the graph generated by the normalization treatments may no longer be undirected.
Although no edges are added or removed,
the edge weights may be modified asymmetrically,
meaning that a single undirected edge in the original graph
may get transformed into two directed edges with different weights
in the result.

Although these normalizations are described
in terms of the raw coinstallation matrix,
they can be applied as treatments to any add-on relational graph.

### Add-on count normalization

This treatment accounts for the popularity of an add-on in terms of
how widely it is coinstalled,
ie. how many different add-ons it appears coinstalled with,
under the assumption that the more widely coinstalled an add-on is,
the less likely it is to be a relevant recommendation.

For each add-on B coinstalled with a given add-on A,
the coinstallation count for (A,B) is divided by
the total number of add-ons that B is coinstalled with.

Given the adjacency matrix $C$,
the treatment divides each each entry $C_{ab}$
by the number of non-zero entries in column $b$.
In terms of the graph representation,
the weight on each edge (A,B) leaving A is divided by
the (in-)degree of the neighbour B.

Intuitively, the total number of coinstalls with B (column sum)
divided by the number of add-ons B is coinstalled with (number of non-zero entries)
represents the average number of coinstallations per coinstalled add-on.
The normalized count for (A,B) can be thought of as the contribution
to this average from add-on A.
This normalization is most effective when comparing add-ons B
with similar total installation counts,
of which some may be coinstalled more widely than others.

This treatment is implemented as [`RowCount`](../taar_lite/recommenders/treatments.py#L87).


### Total relevance normalization

This treatment accounts for the popularity of an add-on in terms of
its overall total number of installations,
under the assumption that the more widely used an add-on is,
the less likely it is to be relevant.

For each add-on B coinstalled with a given add-on A,
the coinstallation count for (A,B) is divided by
the total number of installations of B.

Given the adjacency matrix $C$,
the treatment divides each each entry $C_{ab}$
by the column sum for column $b$.
In terms of the graph representation,
the weight on each edge (A,B) leaving A is divided by
the sum of the weights on all edges entering B.

Intuitively, the normalized count for (A,B) represents
the proportion of B's total installs contributed by profiles
that also have A installed.
Thus, the highest-scoring add-ons B are those which are more likely
to be coinstalled with A than with other add-ons.
We would expect this normalization to do a better job
than the [add-on count normalization](#add-on-count-normalization)
at controlling for the heavy skew of the distribution
of overall install counts.

As discussed [above](#graph-representation), in the raw coinstallation matrix,
row sums are equal to column sums for each add-on
and represent the total number of installs.
For a general add-on relational graph, the matrix may no longer be symmetric,
but the intuition behind the normalization still applies.
In this case, we can view the column sum for B
as an __aggregate relevance score__ over the universe of add-ons,
as it is the sum of relevance scores for B
in relation to each other add-on A.
The normalization converts raw relevance scores to
the proportion of aggregate relevance derived from add-on A.


This treatment is implemented as [`RowSum`](../taar_lite/recommenders/treatments.py#L64).


### Proportional total normalization

This treatment is a rescaled version of the [total relevance normalization](#total-relevance-normalization).
Rather than total installs, popularity is quantified in terms of
the proportion of coinstalls associated with each add-on.
Here, the assumption is that more relevant recommendations tend to account for
a higher proportion out of the given add-on's coinstallations than it does
for other add-ons.

Given add-on A, the coinstallation count for (A,B) for each add-on B
is first divided by the sum of all A's coinstallation counts.
The total relevance normalization is then applied to the resulting proportions.

Given the adjacency matrix $C$,
the treatment first divides each each entry $C_{ab}$
by the row sum for row $a$,
and then divides each entry by the column sum for column $b$
in the resulting matrix.
In terms of the graph representation,
the weight on each edge (A,B) leaving A is first divided by
the sum of the weights on all edges leaving A,
and then the resulting edge weight is divided by
the sum of the weights on all edges entering B.

Intuitively, the first step converts coinstallation counts for A
to the proportion of coinstallations of A allocated to each add-on B.
In the case of general relevance scores, we can think of the row sum for A
as a __relevance budget__,
ie. the total amount of relevance it has available to assign to other add-ons.
The first division has the effect of normalizing each add-on's
relevance budget to 1.
The next step then normalizes each coinstalled add-on's
resulting aggregate relevance to 1.

This treatment is implemented as [`RowNormSum`](../taar_lite/recommenders/treatments.py#L126).


## Graph pruning


# Quality and health metrics


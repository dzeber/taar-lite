
# Overview

The GUID-GUID coinstallation recommender system generates recommendations
for add-ons which are similar to a given add-on,
where similarity is based on the number of profiles
which have both add-ons installed.

As recommendations are only surfaced
for a specific set of add-ons meeting certain criteria,
and depend only on characteristics of the add-ons themselves,
recommendation sets for each add-on can be (and are) computed in advance.

Recommendations are generated as follows:

1. The [input data](#input-data),
    consisting of coinstallation counts for each pair of add-ons,
    is loaded from a precomputed file.
2. For each add-on, we determine a [__candidate list__](#generating-the-candidate-list) of "related" add-ons,
    together with associated __relevance scores__,
    based on the coinstallation data.
    Recommendations for a given add-on will be drawn from its candidate list.
3. Candidate lists may be further adjusted by applying a [__pruning function__](#pruning),
    which is intended to improve the overall recommendation experience
    for the user.
4. Recommendations are [selected](#selecting-recommendations) for a given add-on
    by retaining the N add-ons in the candidate list
    with the highest relevance scores.

Finally, we apply various [metrics](#quality-and-health-metrics) to the coinstallation data, candidate lists, and recommendations,
to evaluate the overall health of the system
and the quality of recommendations.


# Input data

The primary data source used in generating recommendations
is the file `guid_coinstallation.json`,
which is generated by the ETL jobs described in the [README](../README.md).
It contains coinstallation counts for each pair of add-ons
belonging to a filtered list.

Coinstallation counts are computed based on the Telemetry data
submitted by a random sample of recently active Firefox profiles.
For each pair of add-ons in the list,
we count the number of profiles in which both add-ons are installed and enabled.

The data is stored in "sparse matrix representation" as a nested object/dict,
in which each add-on GUID maps to a further object
mapping coinstalled GUIDS to their coinstallation count,
dropping zero counts.
On initializing a [`GuidGuidCoinstallRecommender`](../taar_lite/recommenders/guidguid.py#L10),
it is supplied as `raw_coinstall_dict`.

Using this dataset as the basis for recommendations
entails the following assumptions:

- The set of add-ons appearing in the coinstallation dataset represent
    the universe of known add-ons for the purpose of generating recommendations.
- We are only dealing with add-ons that were coinstalled
    with at least one other add-on on the list
    (otherwise they would not appear in the file at all).
- Profiles with only a single add-on installed do not contribute to the counts.

__TODO:__ How are system add-ons handled? Add a note about this.

In computing relevance scores, we also draw on an auxiliary dataset
containing an overall ranking for each add-on in our list,
read from the file `guid_install_ranking.json`.
This is used to break ties when sorting candidates on relevance score,
and in pruning out rare add-ons.
It is currently computed from overall add-on installation counts
obtained from AMO.

This data is stored as an object/dict mapping add-on GUIDs to rank scores.
On initializing a [`GuidGuidCoinstallRecommender`](../taar_lite/recommenders/guidguid.py#L10),
it is supplied as `tie_breaker_dict`.
It is also used as the `ranking_dict` passed to the [`MinInstallPrune`](../taar_lite/recommenders/treatments.py#L36) treatment.


## Technical note on mathematical representations

It is helpful to consider both matrix and graph representations of the coinstallation data,
as much of the intuition behind the relevance score computation and the pruning steps
is drawn from these representations.


### Matrix representation

The add-on coinstallation data has a natural representation as a matrix $C$,
where rows and columns are indexed by add-on GUIDs,
and entry $C_{ij}$ contains the coinstallation count for the pair of add-ons $i$ and $j$.
Pairs not occurring in the dataset are assigned a count of 0.

The matrix $C$ has the following properties:

- Since the relation of being coinstalled is symmetric,
    the matrix $C$ will be symmetric
    ($C_{ij} = C_{ji}$ for any pair $i,j$).
- The row sum (or column sum, by symmetry) for add-on $i$ gives
    its overall number of installs across profiles considered in the dataset.


### Graph representation

We can also think of the coinstallation data as inducing a graph $G$,
whose vertices are add-ons,
pairs of which are connected by an edge if they are coinstalled at least once.
We interpret the coinstallation counts as edge weights.
Since coinstallation is a symmetric relation, the graph is undirected,
meaning that every edge runs in both directions.
In fact, the matrix $C$ forms the adjacency matrix for this graph.


# Generating the candidate lists

Candidate lists and relevance scores are generated by applying transformations,
referred to as [__treatments__](#treatments),
to the raw coinstallation data.
Treatments generally incorporate normalizations to help the scores
better reflect the notion of relevance,
and balance this against diversity,
eg. by adjusting for high or low overall add-on popularity.
As recommendations are based solely on the treated data,
we are assuming that it encapsulates all the information
necessary in generating recommendations.

We view the coinstallation dataset as an instance
of a more general add-on relational structure,
in which each add-on is associated with a set of "related" add-ons,
each of which is assigned a score
representing the strength of the relationship.
As discussed [above](#graph-representation),
this structure may be represented as a graph
whose edges connect related add-ons,
with weights given by the scores.

Given such a structure, the candidate list for a given add-on A
is simply the list of add-ons related to A
(ie. A's neighbours in the graph)
with associated relevance scores (edge weights).

In this setting, a treatment is a function which takes as input
an add-on relational graph,
and outputs a graph of the same structure,
possibly adding or deleting edges, or modifying the weights.

Treatments are implemented as extensions of the [`BaseTreatment`](../taar_lite/recommenders/treatments.py#L11) class,
which apply a transformation via the `treat()` method.
On initializing a [`GuidGuidCoinstallRecommender`](../taar_lite/recommenders/guidguid.py#L10),
a list of `BaseTreatment` instances are supplied as `treatments`.
When preparing recommendations, the treatments are applied in sequence
to the raw coinstallation data,
and the result is stored as the recommender instance's `treated_graph`.
Candidate lists and relevance scores are then drawn
from the treated dataset.


## Treatments


## Pruning

__TODO:__ how does this fit into the above discussion?

_Pruning steps will also be treatments, and may modify both edges and weights.
However, they attempt to adjust for quality in a way that surfaces in the graph structure
and is not adequately captured by score normalizations.
For example, we may use pruning to
reduce the influence of highly-connected "hub" nodes
in the original coinstallation graph.
Pruning may also be necessary to improve the experience for users
clicking through multiple recommendations on AMO,
ie. walking the recommendation graph,
as the quality of this experience is not captured individually by pairwise scores.
A known problem of this type is short cycles,
in which a user gets recommended back their original add-on after 1 or 2 steps.


# Selecting recommendations

Recommendations for a given add-on A are generated
by ordering A's candidate list by decreasing relevance score
and selecting the first N add-ons from the sorted list.
Ties in relevance score are broken using an additional list
of add-on tie-breaking scores,
by further ordering tied candidates by decreasing tie-breaking score.

Recommendations are requested from a `GuidGuidCoinstallRecommender` instance
using the [`recommend()`](taar_lite/recommenders/guidguid.py#L123) method.
The list of tie-breaking scores was supplied on initialization as `tie_breaker_dict`.
The double ordering is currently implemented by concatenating the two scores
and applying lexicographical ordering on the result.

The version of the GUID-GUID recommender currently in production
defaults to requesting 4 recommendations for each add-on,
which corresponds to the number of display slots on AMO.


# Quality and health metrics

